import subprocess
import os
import tempfile
import librosa
from pydub import AudioSegment
import numpy as np
from scipy import signal
import soundfile as sf

def calculate_duration_from_analysis(picked_audio):
    """Ph√¢n t√≠ch file ƒë·ªÉ l·∫•y duration ch√≠nh x√°c cho 4 nh·ªãp tim (d√πng Librosa)."""
    try:
        y, sr = librosa.load(picked_audio, sr=None)
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
        if len(beats) >= 5:  # C·∫ßn √≠t nh·∫•t 5 beats ƒë·ªÉ c√≥ 4 intervals
            duration = librosa.frames_to_time(beats[4] - beats[0], sr=sr)
            return duration
    except Exception as e:
        print(f"‚ùå Ph√¢n t√≠ch th·∫•t b·∫°i: {e}")
    return None

def get_mean_volume(audio_path):
    """ƒêo mean volume (dBFS) d√πng PyDub."""
    try:
        audio = AudioSegment.from_file(audio_path)
        return audio.dBFS
    except Exception as e:
        print(f"‚ùå ƒêo volume th·∫•t b·∫°i: {e}")
        return -16.0

def run_ffmpeg(command):
    """Ch·∫°y FFmpeg command v√† check success."""
    process = subprocess.run(command, shell=True, capture_output=True, text=True)
    if process.returncode != 0:
        print(f"‚ùå FFmpeg failed: {process.stderr}")
        return False
    return True

def mix_audio(asset_audio, picked_audio, output_path, original_bpm=120, target_bpm=120):
    """Mix audio c·∫£i ti·∫øn: Gi·∫£m threshold silence, tƒÉng cutoff filter, fallback normalize n·∫øu volume th·∫•p."""
    print("üîé ƒêang ph√¢n t√≠ch file ƒë·ªÉ t√¨m 4 nh·ªãp tim ch√≠nh x√°c...")
    tempo_factor = original_bpm / target_bpm
    analyzed_duration = calculate_duration_from_analysis(picked_audio)

    if analyzed_duration is not None:
        duration_seconds = analyzed_duration
        print(f"‚úÖ PH√ÇN T√çCH TH√ÄNH C√îNG: C·∫Øt ch√≠nh x√°c 4 nh·ªãp = {duration_seconds:.3f}s")
    else:
        duration_seconds = 4 * (60.0 / original_bpm)
        print(f"‚ö†Ô∏è Ph√¢n t√≠ch th·∫•t b·∫°i. D√πng c√¥ng th·ª©c chu·∫©n 4 nh·ªãp/BPM: {duration_seconds:.3f}s")

    print(f"üìä Tempo factor: {tempo_factor}")

    with tempfile.TemporaryDirectory() as temp_dir:
        temp_wav_path = os.path.join(temp_dir, 'picked_temp.wav')
        filtered_path = os.path.join(temp_dir, 'picked_filtered.wav')
        silenced_path = os.path.join(temp_dir, 'picked_silenced.wav')
        normalized_picked_path = os.path.join(temp_dir, 'picked_normalized.wav')
        normalized_asset_path = os.path.join(temp_dir, 'asset_normalized.wav')

        # B∆∞·ªõc 1: Chuy·ªÉn ƒë·ªïi picked audio sang WAV (stereo, 44.1kHz)
        print("üîÑ B∆∞·ªõc 1: Chuy·ªÉn ƒë·ªïi sang WAV...")
        convert_cmd = f'ffmpeg -y -i "{picked_audio}" -ac 2 -ar 44100 "{temp_wav_path}"'
        if not run_ffmpeg(convert_cmd):
            return

        # B∆∞·ªõc 2: L·ªçc t·∫°p √¢m (tƒÉng cutoff l√™n 500Hz ƒë·ªÉ gi·ªØ t·∫ßn s·ªë tim thai)
        print("üîä B∆∞·ªõc 2.1: L·ªçc t·∫°p √¢m low-pass (cutoff 500Hz)...")
        y, sr = sf.read(temp_wav_path)
        if y.ndim == 1:
            y = y[:, np.newaxis]  # Convert to 2D if mono

        nyq = 0.5 * sr
        low = 500 / nyq  # TƒÉng cutoff
        b, a = signal.butter(5, low, btype='low')

        padlen = 3 * (max(len(b), len(a)) - 1)
        if y.shape[0] > padlen:
            y_filtered = signal.filtfilt(b, a, y, axis=0)
        else:
            print(f"‚ö†Ô∏è Input too short ({y.shape[0]} samples <= {padlen}), skipping filter.")
            y_filtered = y

        if y_filtered.shape[1] == 1:
            y_filtered = y_filtered.squeeze()

        sf.write(filtered_path, y_filtered, sr)

        # B∆∞·ªõc 2.2: Lo·∫°i b·ªè kho·∫£ng l·∫∑ng (gi·∫£m threshold xu·ªëng -40dB ƒë·ªÉ gi·ªØ √¢m y·∫øu)
        print("üîä B∆∞·ªõc 2.2: Lo·∫°i b·ªè kho·∫£ng l·∫∑ng ƒë·∫ßu (-40dB)...")
        silence_cmd = (
            f'ffmpeg -y -i "{filtered_path}" '
            f'-af silenceremove=start_periods=1:start_duration=0:start_threshold=-40dB:detection=peak '
            f'"{silenced_path}"'
        )
        if not run_ffmpeg(silence_cmd):
            return

        # B∆∞·ªõc 2.3: C·∫Øt 4 nh·ªãp
        print("üîä B∆∞·ªõc 2.3: C·∫Øt ƒë√∫ng 4 nh·ªãp...")
        trim_cmd = f'ffmpeg -y -i "{silenced_path}" -t {duration_seconds} "{normalized_picked_path}"'  # Ch∆∞a normalize
        if not run_ffmpeg(trim_cmd):
            return

        if not os.path.exists(normalized_picked_path) or os.path.getsize(normalized_picked_path) == 0:
            print("‚ùå Trimmed file is empty, fallback to no silence remove.")
            # Fallback: Trim from filtered without silence remove
            fallback_trim_cmd = f'ffmpeg -y -i "{filtered_path}" -t {duration_seconds} "{normalized_picked_path}"'
            run_ffmpeg(fallback_trim_cmd)

        # B∆∞·ªõc 2.4: Chu·∫©n h√≥a picked d√πng PyDub (peak normalize, tr√°nh issue loudnorm v·ªõi file ng·∫Øn)
        print("üîä B∆∞·ªõc 2.4: Chu·∫©n h√≥a √¢m l∆∞·ª£ng picked (PyDub normalize)...")
        picked_audio_seg = AudioSegment.from_file(normalized_picked_path)
        picked_audio_seg = picked_audio_seg.normalize()  # Peak normalize to 0dBFS
        picked_audio_seg.export(normalized_picked_path, format="wav")

        vol_picked_check = picked_audio_seg.dBFS
        print(f"üìä Picked volume after normalize: {vol_picked_check} dB")
        if np.isinf(vol_picked_check) or vol_picked_check < -50:
            print("‚ö†Ô∏è Volume v·∫´n th·∫•p, boost th√™m +10dB.")
            picked_audio_seg = picked_audio_seg + 10
            picked_audio_seg.export(normalized_picked_path, format="wav")

        # B∆∞·ªõc 3: Chu·∫©n h√≥a asset audio (gi·ªØ loudnorm v√¨ file d√†i)
        print("üîä B∆∞·ªõc 3: Chu·∫©n h√≥a √¢m l∆∞·ª£ng asset audio...")
        normalize_asset_cmd = (
            f'ffmpeg -y -i "{asset_audio}" -ar 44100 -ac 2 '
            f'-af loudnorm=I=-16:TP=-1.5:LRA=11 "{normalized_asset_path}"'
        )
        if not run_ffmpeg(normalize_asset_cmd):
            return

        # B∆∞·ªõc 4: Mix (ƒêi·ªÅu ch·ªânh volume d·ª±a tr√™n diff, loop picked, amix h√†i h√≤a)
        print("üéµ B∆∞·ªõc 4: Mix audio (T·ªâ l·ªá 0.6:0.4 ƒë·ªÉ tim thai r√µ h∆°n) - Balancing volumes...")
        vol_asset = get_mean_volume(normalized_asset_path)
        vol_picked = get_mean_volume(normalized_picked_path)
        print(f"üìä Post-norm Volumes -> Asset: {vol_asset} dB, Picked: {vol_picked} dB")

        diff = vol_asset - vol_picked
        asset_filter = ""
        picked_filter = ""
        boost = 0

        if diff > 0:
            print(f"üí° Asset louder by {diff:.2f}dB -> Boosting Picked")
            boost = diff
            asset_filter = f"[0:a]atempo={tempo_factor}[a0];"
            picked_filter = f"[1:a]volume={boost}dB,aloop=loop=-1:size=2e+09[a1];"
        else:
            boost = abs(diff)
            print(f"üí° Picked louder by {boost:.2f}dB -> Boosting Asset")
            asset_filter = f"[0:a]atempo={tempo_factor},volume={boost}dB[a0];"
            picked_filter = f"[1:a]aloop=loop=-1:size=2e+09[a1];"

        # Mix v·ªõi weights 0.6:0.4 (tƒÉng ph·∫ßn tim thai ƒë·ªÉ r√µ h∆°n), th√™m fade
        mix_cmd = (
            f'ffmpeg -y -i "{normalized_asset_path}" -i "{normalized_picked_path}" '
            f'-filter_complex "{picked_filter} {asset_filter} '
            f'[a0][a1]amix=inputs=2:duration=first:dropout_transition=2:weights=0.6 0.4[a]" '
            f'-map "[a]" -c:a libmp3lame -q:a 2 "{output_path}"'
        )
        if run_ffmpeg(mix_cmd):
            print(f"‚úÖ Mixing successful! File saved at {output_path}")
        else:
            print("‚ùå Mixing failed")

# Usage example (thay b·∫±ng paths th·ª±c t·∫ø)
mix_audio("twinkle_star.mp3", "Heartbeat5_bpm140.wav", "demo_version_1.mp3")