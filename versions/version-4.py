import subprocess
import os
import tempfile
import librosa
from pydub import AudioSegment
import numpy as np
import soundfile as sf

def calculate_duration_from_analysis(picked_audio, num_beats=4):
    """PhÃ¢n tÃ­ch Ä‘á»ƒ láº¥y duration cho N nhá»‹p tim."""
    try:
        y, sr = librosa.load(picked_audio, sr=None, duration=30.0)
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
        if isinstance(tempo, np.ndarray):
            tempo = float(tempo[0]) if tempo.size > 0 else 120.0
        if len(beats) >= num_beats + 1:
            duration = librosa.frames_to_time(beats[num_beats] - beats[0], sr=sr)
            return duration, tempo
    except Exception as e:
        print(f"âŒ PhÃ¢n tÃ­ch tháº¥t báº¡i: {e}")
    return None, 120.0

def detect_tempo(audio_path):
    """Tá»± detect tempo cá»§a file audio dÃ¹ng Librosa."""
    try:
        y, sr = librosa.load(audio_path, sr=None, duration=60.0)
        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
        if isinstance(tempo, np.ndarray):
            tempo = float(tempo[0]) if tempo.size > 0 else 120.0
        return tempo
    except Exception as e:
        print(f"âŒ Detect tempo tháº¥t báº¡i: {e}")
        return 120.0

def get_mean_volume(audio_path):
    """Äo mean volume (dBFS) dÃ¹ng PyDub."""
    try:
        audio = AudioSegment.from_file(audio_path)
        return audio.dBFS
    except Exception as e:
        print(f"âŒ Äo volume tháº¥t báº¡i: {e}")
        return -16.0

def run_ffmpeg(command):
    """Cháº¡y FFmpeg command vÃ  check success."""
    process = subprocess.run(command, shell=True, capture_output=True, text=True)
    if process.returncode != 0:
        print(f"âŒ FFmpeg failed: {process.stderr}")
        return False
    return True

def apply_noise_reduction(y, sr):
    """Sá»­ dá»¥ng HPSS tá»« Librosa Ä‘á»ƒ tÃ¡ch percussive (nhá»‹p tim)."""
    y_harmonic, y_percussive = librosa.effects.hpss(y)
    return y_percussive

def time_stretch_heartbeat(input_path, output_path, target_tempo_for_heartbeat, original_heart_tempo):
    """Stretch nhá»‹p tim dÃ¹ng FFmpeg atempo Ä‘á»ƒ trÃ¡nh bug librosa."""
    if original_heart_tempo <= 0 or target_tempo_for_heartbeat <= 0:
        print("âš ï¸ Tempo khÃ´ng há»£p lá»‡, copy nguyÃªn.")
        run_ffmpeg(f'ffmpeg -y -i "{input_path}" "{output_path}"')
        return

    rate = target_tempo_for_heartbeat / original_heart_tempo
    if rate <= 0 or np.isinf(rate) or np.isnan(rate):
        rate = 1.0

    # Giá»›i háº¡n tá»· lá»‡ kÃ©o dÃ i Ä‘á»ƒ trÃ¡nh táº¡o ra quÃ¡ nhiá»u artifact
    if rate > 3.0:
        print(f"âš ï¸ Tá»‘c Ä‘á»™ kÃ©o dÃ i quÃ¡ cao ({rate:.2f}), giá»›i háº¡n á»Ÿ 3.0.")
        rate = 3.0
    elif rate < 0.3:
        print(f"âš ï¸ Tá»‘c Ä‘á»™ kÃ©o dÃ i quÃ¡ tháº¥p ({rate:.2f}), giá»›i háº¡n á»Ÿ 0.3.")
        rate = 0.3

    stretch_cmd = f'ffmpeg -y -i "{input_path}" -filter:a "atempo={rate}" "{output_path}"'
    if not run_ffmpeg(stretch_cmd):
        print("âš ï¸ Stretch tháº¥t báº¡i, copy nguyÃªn.")
        run_ffmpeg(f'ffmpeg -y -i "{input_path}" "{output_path}"')

def tune_to_432hz(input_path, output_path):
    cmd = f'ffmpeg -y -i "{input_path}" -af "asetrate=44100*432/440,aresample=44100,atempo=1.0185185185185186" "{output_path}"'
    run_ffmpeg(cmd)

def mix_audio_v4(asset_audio, picked_audio, output_path):
    """Mix cáº£i tiáº¿n: Tá»± detect tempo, stretch tim khá»›p 2x tempo nháº¡c, tá»‰ lá»‡ 0.8:0.2, tinh chá»‰nh norm, 432Hz tuning."""
    print("ğŸ” PhÃ¢n tÃ­ch nhá»‹p tim...")
    duration_seconds, heart_tempo = calculate_duration_from_analysis(picked_audio, num_beats=4)
    if duration_seconds is None:
        duration_seconds = 4 * (60.0 / heart_tempo) + 0.5

    music_tempo = detect_tempo(asset_audio)
    print(f"ğŸ“Š Heart BPM: {heart_tempo:.2f}, Music BPM: {music_tempo:.2f}")

    with tempfile.TemporaryDirectory() as temp_dir:
        temp_wav_path = os.path.join(temp_dir, 'picked_temp.wav')
        denoised_path = os.path.join(temp_dir, 'picked_denoised.wav')
        stretched_path = os.path.join(temp_dir, 'picked_stretched.wav')
        normalized_picked_path = os.path.join(temp_dir, 'picked_normalized.wav')
        normalized_asset_path = os.path.join(temp_dir, 'asset_normalized.wav')
        mixed_temp_path = os.path.join(temp_dir, 'mixed_temp.mp3')
        tuned_output_path = output_path  # Final tuned

        # BÆ°á»›c 1: Convert to WAV (mono cho nhá»‹p tim)
        print("ğŸ”„ BÆ°á»›c 1: Chuyá»ƒn Ä‘á»•i nhá»‹p tim sang WAV (mono)...")
        convert_cmd = f'ffmpeg -y -i "{picked_audio}" -ac 1 -ar 44100 "{temp_wav_path}"'
        if not run_ffmpeg(convert_cmd):
            return

        # BÆ°á»›c 2: Khá»­ táº¡p Ã¢m HPSS
        print("ğŸ”Š BÆ°á»›c 2: Khá»­ táº¡p Ã¢m HPSS...")
        y, sr = sf.read(temp_wav_path)
        if y.ndim > 1:
            y = np.mean(y, axis=1)
        y_denoised = apply_noise_reduction(y, sr)
        sf.write(denoised_path, y_denoised, sr)

        # BÆ°á»›c 3: Stretch nhá»‹p tim Ä‘á»ƒ khá»›p 2x tempo nháº¡c
        print(f"ğŸ”Š BÆ°á»›c 3: Stretch nhá»‹p tim tá»« {heart_tempo:.2f} BPM Ä‘á»ƒ khá»›p {music_tempo * 2:.2f} BPM cá»§a nháº¡c...")
        target_heartbeat_tempo = music_tempo * 2
        time_stretch_heartbeat(denoised_path, stretched_path, target_heartbeat_tempo, heart_tempo)

        # BÆ°á»›c 4: Trim & Normalize picked (loáº¡i bá» giáº£m 14dB cá»‘ Ä‘á»‹nh)
        print("ğŸ”Š BÆ°á»›c 4: Cáº¯t & chuáº©n hÃ³a nhá»‹p tim (tinh chá»‰nh Ä‘á»ƒ giáº£m noise)...")
        picked_seg = AudioSegment.from_file(stretched_path)

        # TÃ­nh láº¡i duration sau stretch cho 4 nhá»‹p tim á»Ÿ tá»‘c Ä‘á»™ má»›i
        # 4 nhá»‹p tim á»Ÿ target_heartbeat_tempo
        adjusted_duration_ms = (4 * (60.0 / target_heartbeat_tempo)) * 1000

        picked_seg = picked_seg[:int(adjusted_duration_ms)]
        picked_seg = picked_seg.normalize() # Chá»‰ normalize, khÃ´ng giáº£m cá»‘ Ä‘á»‹nh 14dB

        # Náº¿u volume váº«n quÃ¡ tháº¥p sau normalize, cÃ³ thá»ƒ boost nháº¹ nhÃ ng Ä‘á»ƒ trÃ¡nh noise
        if picked_seg.dBFS < -25:
             print("âš ï¸ Volume nhá»‹p tim váº«n tháº¥p, boost nháº¹ +3dB.")
             picked_seg += 3

        picked_seg.export(normalized_picked_path, format="wav")

        # BÆ°á»›c 5: Normalize asset
        print("ğŸ”Š BÆ°á»›c 5: Chuáº©n hÃ³a Ã¢m lÆ°á»£ng nháº¡c...")
        normalize_asset_cmd = (
            f'ffmpeg -y -i "{asset_audio}" -ar 44100 -ac 2 '
            f'-af loudnorm=I=-16:TP=-1.5:LRA=11 "{normalized_asset_path}"'
        )
        if not run_ffmpeg(normalize_asset_cmd):
            return

        # BÆ°á»›c 6: Mix vá»›i tá»‰ lá»‡ má»›i 0.75 (nháº¡c) : 0.25 (tim)
        print("ğŸµ BÆ°á»›c 6: Mix vá»›i tá»‰ lá»‡ 0.75:0.25 (nháº¡c : tim) vÃ  cÃ¢n báº±ng Ã¢m lÆ°á»£ng...")
        vol_asset = get_mean_volume(normalized_asset_path)
        vol_picked = get_mean_volume(normalized_picked_path)
        print(f"ğŸ“Š Volumes â†’ Asset: {vol_asset:.2f} dB, Picked: {vol_picked:.2f} dB")

        # CÃ¢n báº±ng Ä‘á»™ng, Æ°u tiÃªn nháº¡c ná»•i báº­t hÆ¡n theo tá»‰ lá»‡ 0.8
        diff = vol_asset - vol_picked
        # Náº¿u asset nhá» hÆ¡n picked, tÄƒng asset lÃªn (diff < 0 => -diff > 0)
        # ThÃªm 2dB cho asset Ä‘á»ƒ Ä‘áº£m báº£o nÃ³ luÃ´n ná»•i báº­t hÆ¡n
        asset_filter = f"[0:a]volume={max(0, -diff + 2)}dB[a0];"
        # Náº¿u picked nhá» hÆ¡n asset, tÄƒng picked lÃªn (diff > 0)
        picked_filter = f"[1:a]volume={max(0, diff)}dB,aloop=loop=-1:size=2e+09[a1];"

        mix_cmd = (
            f'ffmpeg -y -i "{normalized_asset_path}" -i "{normalized_picked_path}" '
            f'-filter_complex "{asset_filter}{picked_filter}[a0][a1]amix=inputs=2:duration=first:dropout_transition=3:weights=0.75 0.25[a]" '
            f'-map "[a]" -c:a libmp3lame -q:a 2 "{mixed_temp_path}"'
        )
        if run_ffmpeg(mix_cmd):
            print(f"âœ… Mixing successful! Tuning to 432Hz...")
            tune_to_432hz(mixed_temp_path, tuned_output_path)
            print(f"âœ… Tuned output saved at {output_path}")
        else:
            print("âŒ Mixing failed")

# Sá»­ dá»¥ng vá»›i file cá»§a báº¡n (VÃ­ dá»¥)
mix_audio_v4("twinkle_star.mp3", "Heartbeat5_bpm140.wav", "demo_version_4.1.mp3")